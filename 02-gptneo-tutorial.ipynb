{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "812f5c19-b7f2-4609-aedc-87a6bce5a24a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a63aac2f81f84f528cb83155551edea4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.32k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b8fc3f0a5a44244977154f5d25252bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/4.95G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c617efa3ae944806883faf796e75967c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/779k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18c691c1e44f4fb9a7876f93c1bbc47b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/446k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1867edc9aa6549658d795e63a00374c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/90.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c09f36c252014d399725edf538b7bb1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/200 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import GPTNeoForCausalLM, GPT2Tokenizer\n",
    "\n",
    "\n",
    "device = 'cuda:0'\n",
    "model_name = 'EleutherAI/gpt-neo-1.3B'\n",
    "\n",
    "model = GPTNeoForCausalLM.from_pretrained(model_name)\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e55f2375-3640-4edb-b0ff-b385cdc161c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "prompt = \"Transformers are the\"\n",
    "input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e5cff08-2a0a-4778-bc36-78de9cdaad97",
   "metadata": {},
   "source": [
    "# 텍스트 생성하기\n",
    "\n",
    "- 공부를 위해서 직접 구현해보자!\n",
    "- 급한사람은 아래 코드를 바로 이용가능하다\n",
    "\n",
    "```\n",
    "gen_tokens = model.generate(\n",
    "    input_ids,\n",
    "    do_sample=True,\n",
    "    temperature=0.9,\n",
    "    max_length=100,\n",
    ")\n",
    "gen_text = tokenizer.batch_decode(gen_tokens)[0]\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e43bbb9-c205-4bc0-a35a-2be0cfda729d",
   "metadata": {},
   "source": [
    "### 그리디 버전으로 텍스트 생성\n",
    "- 다양성이 필요한 작업보다 결정적이고 사실적으로 정확한 출력이 필요한 수식에 유리\n",
    "- 혹은 빔서치를 활용할 수도 있다!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7bd094b7-6760-4325-bd05-1000bbc68772",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "iterations = []\n",
    "\n",
    "n_steps = 8\n",
    "choices_per_step = 5\n",
    "\n",
    "with torch.no_grad():\n",
    "    for _ in range(n_steps):\n",
    "        iteration = dict()\n",
    "        iteration['input'] = tokenizer.decode(input_ids[0]) \n",
    "        output = model(input_ids=input_ids)\n",
    "        \n",
    "        # 첫번째 배치의 마지막 토큰의 로짓을 선택해 소프트맥스 적용\n",
    "        next_token_logits = output.logits[0, -1, :]\n",
    "        next_token_probs = torch.softmax(next_token_logits, dim=-1)\n",
    "        \n",
    "        # 그리디 방식으로 디코딩 수행\n",
    "        # 각 스텝별로 확률이 가장 높은 토큰을 선택\n",
    "        sorted_ids = torch.argsort(next_token_probs, dim=-1, descending=True)\n",
    "        for choice_idx in range(choices_per_step):\n",
    "            token_id = sorted_ids[choice_idx]\n",
    "            token_prob = next_token_probs[token_id].cpu().numpy()\n",
    "            token_choice = (f'{tokenizer.decode(token_id)} ({100 * token_prob:.2f}%)')\n",
    "            iteration[f'Choice {choice_idx+1}'] = token_choice\n",
    "            \n",
    "            #예측한 다음 토큰을 입력에 추가\n",
    "        input_ids = torch.cat([input_ids, sorted_ids[None, 0, None]], dim=-1)\n",
    "        iterations.append(iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fc1a92e9-ea29-4644-8345-2e38d6e1aec8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>Choice 1</th>\n",
       "      <th>Choice 2</th>\n",
       "      <th>Choice 3</th>\n",
       "      <th>Choice 4</th>\n",
       "      <th>Choice 5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Transformers are the</td>\n",
       "      <td>most (20.53%)</td>\n",
       "      <td>best (6.12%)</td>\n",
       "      <td>coolest (2.24%)</td>\n",
       "      <td>Transformers (2.22%)</td>\n",
       "      <td>biggest (2.09%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Transformers are the most</td>\n",
       "      <td>popular (25.45%)</td>\n",
       "      <td>successful (7.44%)</td>\n",
       "      <td>iconic (3.54%)</td>\n",
       "      <td>famous (3.00%)</td>\n",
       "      <td>beloved (2.99%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Transformers are the most popular</td>\n",
       "      <td>toys (8.64%)</td>\n",
       "      <td>toy (6.75%)</td>\n",
       "      <td>and (5.74%)</td>\n",
       "      <td>movie (4.42%)</td>\n",
       "      <td>franchise (4.18%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Transformers are the most popular toys</td>\n",
       "      <td>in (35.96%)</td>\n",
       "      <td>of (13.08%)</td>\n",
       "      <td>for (9.05%)</td>\n",
       "      <td>ever (4.70%)</td>\n",
       "      <td>and (2.87%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Transformers are the most popular toys in</td>\n",
       "      <td>the (69.00%)</td>\n",
       "      <td>America (6.14%)</td>\n",
       "      <td>Japan (2.12%)</td>\n",
       "      <td>children (2.08%)</td>\n",
       "      <td>American (1.52%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Transformers are the most popular toys in the</td>\n",
       "      <td>world (68.31%)</td>\n",
       "      <td>United (4.99%)</td>\n",
       "      <td>Transformers (3.71%)</td>\n",
       "      <td>US (2.67%)</td>\n",
       "      <td>U (2.46%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Transformers are the most popular toys in the ...</td>\n",
       "      <td>. (42.39%)</td>\n",
       "      <td>, (28.99%)</td>\n",
       "      <td>and (8.55%)</td>\n",
       "      <td>today (3.27%)</td>\n",
       "      <td>right (3.25%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Transformers are the most popular toys in the ...</td>\n",
       "      <td>They (13.98%)</td>\n",
       "      <td>The (6.58%)</td>\n",
       "      <td>But (3.99%)</td>\n",
       "      <td>There (3.94%)</td>\n",
       "      <td>And (3.63%)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               input  ...            Choice 5\n",
       "0                               Transformers are the  ...     biggest (2.09%)\n",
       "1                          Transformers are the most  ...     beloved (2.99%)\n",
       "2                  Transformers are the most popular  ...   franchise (4.18%)\n",
       "3             Transformers are the most popular toys  ...         and (2.87%)\n",
       "4          Transformers are the most popular toys in  ...    American (1.52%)\n",
       "5      Transformers are the most popular toys in the  ...           U (2.46%)\n",
       "6  Transformers are the most popular toys in the ...  ...       right (3.25%)\n",
       "7  Transformers are the most popular toys in the ...  ...         And (3.63%)\n",
       "\n",
       "[8 rows x 6 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(iterations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed5e0c0a-fe0a-4203-a4d8-d47d95dec336",
   "metadata": {},
   "source": [
    "- 사실 Spell 생성은 다양한게 중요하니까\n",
    "- 여기에 좀 더 적합한 샘플링 방법을 사용\n",
    "- \n",
    "\n",
    "### 샘플링 방법으로 텍스트 생성\n",
    "\n",
    "- 확률이 가장 높은 K 토큰에서만 샘플링해서 확률이 낮은 토큰을 피함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8a62cce5-2acf-44cd-935a-95b6c0ab4b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 8\n",
    "prompt = \"Transformers are the\"\n",
    "input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ab33d112-a9aa-4039-b593-2216f8386175",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformers are the most popular series in\n"
     ]
    }
   ],
   "source": [
    "output_temp = model.generate(input_ids, max_length=max_length, do_sample=True, temperature=0.5, top_k=10, pad_token_id=5025)\n",
    "print(tokenizer.decode(output_temp[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db33839-c003-4c7b-aa3b-c1f3d71b6104",
   "metadata": {},
   "source": [
    "## 모델 평가를 위한 BLEU 점수 구하기\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8b5b9210-79ca-48d2-91af-cdea4df64494",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_metric\n",
    "\n",
    "bleu_metric = load_metric('sacrebleu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9586463c-5813-4150-97c9-5e609d8f3ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3917b2d9-b892-4aa2-aa7a-05db74305758",
   "metadata": {},
   "outputs": [],
   "source": [
    "bleu_metric.add(prediction='the cat is on mat', reference=['the cat in on the mat'])\n",
    "results = bleu_metric.compute(smooth_method='floor', smooth_value=0)\n",
    "results['precisions'] = [np.round(p,2) for p in results['precisions']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3a5c58c6-592b-441d-bfbd-548329c492a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 0.0,\n",
       " 'counts': [4, 1, 0, 0],\n",
       " 'totals': [5, 4, 3, 2],\n",
       " 'precisions': [80.0, 25.0, 0.0, 0.0],\n",
       " 'bp': 0.8187307530779819,\n",
       " 'sys_len': 5,\n",
       " 'ref_len': 6}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed58b037-6020-4171-8948-7ffca29d414f",
   "metadata": {},
   "source": [
    "### 참고링크\n",
    "\n",
    "- 트랜스포머를 활용한 자연어 처리\n",
    "- https://huggingface.co/docs/transformers/model_doc/gpt_neo#overview"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jiwon_py37",
   "language": "python",
   "name": "jiwon_py37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
